{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8LTaefqDJMIn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Instantiate the dataset API\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train),(x_test, y_test) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia2OadhALJjS"
   },
   "source": [
    "## Creating a Callback class\n",
    "\n",
    "You can create a callback by defining a class that inherits the [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback) base class. From there, you can define available methods to set where the callback will be executed. For instance below, you will use the [on_epoch_end()](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) method to check the loss at each training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>An overview of callback methods</h3>\n",
    "\n",
    "* Global methods\n",
    "\n",
    ">on_(train|test|predict)_begin(self, logs=None) Called at the beginning of fit/evaluate/predict.\n",
    "\n",
    ">on_(train|test|predict)_end(self, logs=None) Called at the end of fit/evaluate/predict.\n",
    "\n",
    "* Batch-level methods for training/testing/predicting\n",
    "\n",
    "> on_(train|test|predict)_batch_begin(self, batch, logs=None)\n",
    "Called right before processing a batch during training/testing/predicting.\n",
    "\n",
    "> on_(train|test|predict)_batch_end(self, batch, logs=None)\n",
    "Called at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the metrics results.\n",
    "\n",
    "* Epoch-level methods (training only)\n",
    "\n",
    ">on_epoch_begin(self, epoch, logs=None)\n",
    "Called at the beginning of an epoch during training.\n",
    "\n",
    ">on_epoch_end(self, epoch, logs=None)\n",
    "Called at the end of an epoch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uuRmQZWVJAJH"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Starting training; got log keys: {}\".format(keys))\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "        print(\"Final Loss: {}\".format(logs[\"loss\"]))\n",
    "        print(\"Final accuracy: {}\".format(logs[\"accuracy\"]))\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''\n",
    "        Halts the training after reaching 60 percent accuracy\n",
    "\n",
    "        Args:\n",
    "          epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "          logs (dict) - metric results from the training epoch\n",
    "        '''\n",
    "\n",
    "        # Check accuracy\n",
    "        if(logs.get('loss') < 0.4):\n",
    "\n",
    "          # Stop if threshold is met\n",
    "          print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "          self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xlXeLkFeMn8"
   },
   "source": [
    "## Define and compile the model\n",
    "\n",
    "Next, you will define and compile the model. The architecture will be similar to the one you built in the previous lab. Afterwards, you will set the optimizer, loss, and metrics that you will use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7JXxMg3TpzER"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eLe4cPZe-ui"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Now you are ready to train the model. To set the callback, simply set the `callbacks` parameter to the `myCallback` instance you declared before. Run the cell below and observe what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a list of callbacks (as the keyword argument callbacks) to the following model methods:\n",
    "\n",
    "\n",
    "* keras.Model.fit()\n",
    "* keras.Model.evaluate()\n",
    "* keras.Model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLXTB32de3_e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training; got log keys: []\n",
      "Start epoch 0 of training; got log keys: []\n",
      "Epoch 1/10\n",
      " 511/1875 [=======>......................] - ETA: 4s - loss: 0.6063 - accuracy: 0.7875"
     ]
    }
   ],
   "source": [
    "# Train the model with a callback\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W2_Lab_2_callbacks.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C1/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb",
     "timestamp": 1638884482962
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
